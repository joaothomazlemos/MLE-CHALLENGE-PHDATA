"""
Simple Model Evaluation Script for House Price Prediction

This script answers two key questions from the project requirement:
1. How well will the model generalize to new data?
2. Has the model appropriately fit the dataset? (overfitting/underfitting check)

Based on create_model.py with focus on practical business insights.
"""

import json
import pickle
import warnings
from typing import List, Tuple

import numpy as np
import pandas as pd
from sklearn import model_selection, metrics

warnings.filterwarnings('ignore')

SALES_PATH = "data/kc_house_data.csv"
DEMOGRAPHICS_PATH = "data/zipcode_demographics.csv"
MODEL_PATH = "model/model.pkl"
FEATURES_PATH = "model/model_features.json"

SALES_COLUMN_SELECTION = [
    'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',
    'sqft_above', 'sqft_basement', 'zipcode'
]

def load_data() -> Tuple[pd.DataFrame, pd.Series]:
    """Load and prepare the training data (same as create_model.py)."""
    print("üìä Loading training data...")
    
    data = pd.read_csv(SALES_PATH,
                       usecols=SALES_COLUMN_SELECTION,
                       dtype={'zipcode': str})
    
    demographics = pd.read_csv(DEMOGRAPHICS_PATH,
                               dtype={'zipcode': str})

    merged_data = data.merge(demographics, how="left", on="zipcode").drop(columns="zipcode")
    
    y = merged_data.pop('price')
    X = merged_data
    
    print(f"   ‚Ä¢ Training samples: {len(X):,}")
    print(f"   ‚Ä¢ Features: {len(X.columns)}")
    print(f"   ‚Ä¢ Price range: ${y.min():,.0f} - ${y.max():,.0f}")
    
    return X, y

def load_trained_model():
    """Load the trained model and features."""
    print("\nü§ñ Loading trained model...")
    
    with open(MODEL_PATH, 'rb') as f:
        model = pickle.load(f)
    
    with open(FEATURES_PATH, 'r') as f:
        features = json.load(f)
    
    print(f"   ‚Ä¢ Model type: {type(model).__name__}")
    print(f"   ‚Ä¢ Features: {len(features)}")
    
    return model, features

def evaluate_generalization(X, y, model):
    """
    Answer: How well will the model generalize to new data?
    Method: Train/test split to simulate unseen data
    """
    print("\nüéØ QUESTION 1: How well will the model generalize to new data?")
    print("-" * 60)
    
    X_train, X_test, y_train, y_test = model_selection.train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=True
    )
    
    print(f"   ‚Ä¢ Training on {len(X_train):,} houses")
    print(f"   ‚Ä¢ Testing on {len(X_test):,} houses (simulating new data)")
    
    model.fit(X_train, y_train)
    
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    train_mae = metrics.mean_absolute_error(y_train, y_train_pred)
    test_mae = metrics.mean_absolute_error(y_test, y_test_pred)
    
    train_r2 = metrics.r2_score(y_train, y_train_pred)
    test_r2 = metrics.r2_score(y_test, y_test_pred)
    
    train_mape = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100
    test_mape = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100
    
    print(f"\n   üìà Performance Metrics:")
    print(f"   ‚Ä¢ Training MAE: ${train_mae:,.0f} ({train_mape:.1f}% error)")
    print(f"   ‚Ä¢ Test MAE: ${test_mae:,.0f} ({test_mape:.1f}% error)")
    print(f"   ‚Ä¢ Training R¬≤: {train_r2:.3f}")
    print(f"   ‚Ä¢ Test R¬≤: {test_r2:.3f}")
    
    mae_ratio = test_mae / train_mae
    r2_diff = train_r2 - test_r2
    
    print(f"\n   üîç Generalization Analysis:")
    print(f"   ‚Ä¢ Test MAE is {mae_ratio:.2f}x training MAE")
    print(f"   ‚Ä¢ R¬≤ drops by {r2_diff:.3f} on test data")
    
    print(f"\n   üìä Interpretation:")
    if mae_ratio <= 1.15 and r2_diff <= 0.08:
        print("   ‚úÖ EXCELLENT: Model generalizes very well to new data!")
        generalization = "Excellent"
    elif mae_ratio <= 1.35 and r2_diff <= 0.15:
        print("   ‚úÖ GOOD: Model should perform well on new houses")
        generalization = "Good"
    elif mae_ratio <= 1.5 and r2_diff <= 0.25:
        print("   ‚ö†Ô∏è  FAIR: Model has some generalization challenges")
        generalization = "Fair"
    else:
        print("   ‚ùå POOR: Model may not generalize well to new data")
        generalization = "Poor"
    
    return {
        'train_mae': train_mae, 'test_mae': test_mae,
        'train_r2': train_r2, 'test_r2': test_r2,
        'train_mape': train_mape, 'test_mape': test_mape,
        'mae_ratio': mae_ratio, 'r2_diff': r2_diff,
        'generalization': generalization
    }

def evaluate_model_fit(X, y, model):
    """
    Answer: Has the model appropriately fit the dataset?
    Method: Cross-validation + overfitting detection
    """
    print("\nüéØ QUESTION 2: Has the model appropriately fit the dataset?")
    print("-" * 60)
    
    print("   üìä Running 5-fold cross-validation...")
    cv_scores = model_selection.cross_val_score(
        model, X, y, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1
    )
    cv_mae_scores = -cv_scores
    
    cv_r2_scores = model_selection.cross_val_score(
        model, X, y, cv=5, scoring='r2', n_jobs=-1
    )
    
    print(f"   ‚Ä¢ CV MAE: ${cv_mae_scores.mean():,.0f} ¬± ${cv_mae_scores.std():,.0f}")
    print(f"   ‚Ä¢ CV R¬≤: {cv_r2_scores.mean():.3f} ¬± {cv_r2_scores.std():.3f}")
    
    X_train, X_test, y_train, y_test = model_selection.train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    model.fit(X_train, y_train)
    
    train_mae = metrics.mean_absolute_error(y_train, model.predict(X_train))
    test_mae = metrics.mean_absolute_error(y_test, model.predict(X_test))
    
    mae_ratio = test_mae / train_mae
    
    print(f"\n   üîç Overfitting Analysis:")
    print(f"   ‚Ä¢ Training MAE: ${train_mae:,.0f}")
    print(f"   ‚Ä¢ Test MAE: ${test_mae:,.0f}")
    print(f"   ‚Ä¢ Ratio (test/train): {mae_ratio:.2f}")
    
    print(f"\n   üìä Model Fit Assessment:")
    if mae_ratio <= 1.15:
        print("   ‚úÖ EXCELLENT FIT: Model is well-balanced, no overfitting")
        model_fit = "Excellent Fit"
    elif mae_ratio <= 1.35:
        print("   ‚úÖ GOOD FIT: Model generalizes well with minimal overfitting")
        model_fit = "Good Fit"
    elif mae_ratio <= 1.5:
        print("   ‚ö†Ô∏è  SLIGHT OVERFITTING: Model memorizes training data a bit")
        model_fit = "Slight Overfitting"
    else:
        print("   ‚ùå OVERFITTING: Model memorizes training data too much")
        model_fit = "Overfitting"
    
    cv_r2_mean = cv_r2_scores.mean()
    if cv_r2_mean >= 0.8:
        performance = "Excellent"
    elif cv_r2_mean >= 0.7:
        performance = "Good"
    elif cv_r2_mean >= 0.6:
        performance = "Fair"
    else:
        performance = "Poor"
    
    print(f"   ‚Ä¢ Overall Performance: {performance} (R¬≤ = {cv_r2_mean:.3f})")
    
    return {
        'cv_mae_mean': cv_mae_scores.mean(),
        'cv_mae_std': cv_mae_scores.std(),
        'cv_r2_mean': cv_r2_mean,
        'cv_r2_std': cv_r2_scores.std(),
        'mae_ratio': mae_ratio,
        'model_fit': model_fit,
        'performance': performance
    }

def price_range_analysis(X, y, model):
    """Analyze how well the model performs across different price ranges."""
    print("\nüéØ BONUS: Performance across price ranges")
    print("-" * 60)
    
    low_price = y <= y.quantile(0.33)
    mid_price = (y > y.quantile(0.33)) & (y <= y.quantile(0.67))
    high_price = y > y.quantile(0.67)
    
    ranges = [
        ("Low Price", low_price, f"${y[low_price].min():,.0f} - ${y[low_price].max():,.0f}"),
        ("Mid Price", mid_price, f"${y[mid_price].min():,.0f} - ${y[mid_price].max():,.0f}"),
        ("High Price", high_price, f"${y[high_price].min():,.0f} - ${y[high_price].max():,.0f}")
    ]
    
    model.fit(X, y)
    predictions = model.predict(X)
    
    print(f"   üìä Performance by Price Range:")
    for name, mask, price_range in ranges:
        if mask.sum() > 0:
            range_mae = metrics.mean_absolute_error(y[mask], predictions[mask])
            range_r2 = metrics.r2_score(y[mask], predictions[mask])
            range_mape = np.mean(np.abs((y[mask] - predictions[mask]) / y[mask])) * 100
            
            print(f"   ‚Ä¢ {name:10} ({mask.sum():,} houses): MAE=${range_mae:,.0f}, R¬≤={range_r2:.3f}, Error={range_mape:.1f}%")
            print(f"     Range: {price_range}")

def generate_business_recommendations(gen_results, fit_results):
    """Generate actionable recommendations for Sound Realty."""
    print("\nüíº BUSINESS RECOMMENDATIONS FOR SOUND REALTY")
    print("=" * 60)
    
    recommendations = []
    
    if gen_results['generalization'] in ['Excellent', 'Good']:
        recommendations.append("‚úÖ The model is ready for production use on new houses")
    else:
        recommendations.append("‚ö†Ô∏è Consider collecting more training data before deployment")
    
    if fit_results['model_fit'] in ['Overfitting']:
        recommendations.append("‚ö†Ô∏è The model may be too complex - consider simpler approaches")
    elif fit_results['model_fit'] in ['Good Fit', 'Excellent Fit']:
        recommendations.append("‚úÖ Model shows good balance between bias and variance")
    
    if fit_results['performance'] in ['Good', 'Excellent']:
        recommendations.append("‚úÖ Model performance is suitable for business use")
        recommendations.append(f"üìä Expect typical prediction errors of ~${gen_results['test_mae']:,.0f}")
    else:
        recommendations.append("‚ö†Ô∏è Consider feature engineering or different algorithms for better accuracy")
    
    error_pct = gen_results['test_mape']
    if error_pct < 12:
        recommendations.append(f"‚úÖ {error_pct:.1f}% average error is excellent for real estate")
    elif error_pct < 20:
        recommendations.append(f"‚úÖ {error_pct:.1f}% average error is acceptable for real estate")
    else:
        recommendations.append(f"‚ö†Ô∏è {error_pct:.1f}% average error may be too high for some use cases")
    
    recommendations.extend([
        "üìà Consider updating the model quarterly with new sales data",
        "üéØ Monitor prediction accuracy on actual sales to validate performance",
        "üîç Be cautious with predictions on unusual properties (very high/low prices)"
    ])
    
    for i, rec in enumerate(recommendations, 1):
        print(f"   {i}. {rec}")

def main():
    """Main evaluation function."""
    print("üè† Sound Realty Model Evaluation")
    print("üìã Answering: Will this model work well for new houses?")
    print("=" * 60)
    
    X, y = load_data()
    model, features = load_trained_model()
    
    gen_results = evaluate_generalization(X, y, model)
    fit_results = evaluate_model_fit(X, y, model)
    
    price_range_analysis(X, y, model)
    
    generate_business_recommendations(gen_results, fit_results)
    
    print(f"\n" + "=" * 60)
    print("üìã EXECUTIVE SUMMARY")
    print("=" * 60)
    print(f"‚úÖ Model Generalization: {gen_results['generalization']}")
    print(f"‚úÖ Model Fit: {fit_results['model_fit']}")
    print(f"‚úÖ Overall Performance: {fit_results['performance']}")
    print(f"üí∞ Expected Error: ${gen_results['test_mae']:,.0f} ({gen_results['test_mape']:.1f}%)")
    print(f"üìä Model explains {fit_results['cv_r2_mean']:.1%} of price variation")

if __name__ == "__main__":
    main()